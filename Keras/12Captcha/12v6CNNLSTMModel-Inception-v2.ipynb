{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Merge\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import genfromtxt\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import copy\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Part 1 -> defines\n",
    "img_channels, img_rows, img_cols = 3, 299, 299\n",
    "max_caption_len = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Part 2 -> get data\n",
    "def get_im(path):\n",
    "    # Load as grayscale\n",
    "    img = cv2.imread(path)\n",
    "    # Reduce size\n",
    "    resized = cv2.resize(img, (img_cols, img_rows))\n",
    "    return resized\n",
    "\n",
    "\n",
    "def encode(str, num_rows):\n",
    "    \"\"\"\n",
    "    One hot encodes str\n",
    "    params: num_rows for keeping the num_rows the same\n",
    "    \"\"\"\n",
    "    \n",
    "    chars = '0123456789.'\n",
    "    char_to_nr = dict( (ch, nr) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    nr_to_char = dict( (nr, ch) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    \n",
    "    #Matrice of zeros with the following shape [number_of_lines][max_different_chars_per_line]\n",
    "    x = np.zeros((num_rows, len(chars)))\n",
    "        \n",
    "    #Do the encoding\n",
    "    for i, ch in enumerate(str):\n",
    "        x[i, char_to_nr[ch]] = True\n",
    "        \n",
    "    return x    \n",
    "        \n",
    "def decode(x, calc_argmax = True):\n",
    "    \"\"\"\n",
    "    Decodes x and returns it\n",
    "    \"\"\"\n",
    "        \n",
    "    chars = '0123456789.'\n",
    "    char_to_nr = dict( (ch, nr) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    nr_to_char = dict( (nr, ch) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    \n",
    "    if calc_argmax:\n",
    "        x = x.argmax(axis = -1)\n",
    "        \n",
    "    return ''.join(nr_to_char[x] for x in x)\n",
    "    \n",
    "def encodeAll(data):\n",
    "    chars = '0123456789.'\n",
    "    MAX_LEN_Y = 1\n",
    "    \n",
    "    # [number_of_lines][total_different_chars_possible]\n",
    "    y = np.zeros( (len(data), len(chars)), dtype = np.bool )\n",
    "    \n",
    "    for i, line in enumerate(data):\n",
    "        y[i] = encode(line, MAX_LEN_Y)\n",
    "    \n",
    "    return y\n",
    "\n",
    "def pad(str, size):\n",
    "    newStr = copy.deepcopy(str)\n",
    "    while(len(newStr) < size):\n",
    "        newStr.append(10)\n",
    "        \n",
    "    return newStr\n",
    "\n",
    "def getDataManually(path):\n",
    "    X = []\n",
    "    X2 = []\n",
    "    y = []\n",
    "    \n",
    "\n",
    "    for dir in os.listdir(path):\n",
    "        crtPath = os.path.join(path, dir, \"*.png\")\n",
    "        \n",
    "        files = glob.glob(crtPath)\n",
    "        for fl in files:\n",
    "             # X\n",
    "             fl = os.path.join(cwd, fl)\n",
    "             img = get_im(fl)\n",
    "            \n",
    "             # Y\n",
    "             crtSeq = ''\n",
    "             crtSeqList = []\n",
    "             \n",
    "             X.append(img)\n",
    "             X2.append( pad(crtSeqList, 3) )\n",
    "             y.append( str(dir[0]) )\n",
    "                \n",
    "             for i in range( len(str(dir)) - 1 ):\n",
    "                    crtSeq += dir[i]\n",
    "                    crtSeqList.append( int(dir[i]) )\n",
    "                    \n",
    "                    X.append(img)\n",
    "                    X2.append( pad(crtSeqList, 3) )\n",
    "                    y.append( str(dir[i + 1]) )\n",
    "                    \n",
    "             if len(X) % 1000 == 0:\n",
    "                 print(\"Picture \" + str(len(X)) + \" added from path: \", fl)\n",
    "    \n",
    "    return X, X2, y\n",
    "\n",
    "def getData():\n",
    "    x_train, x_train2, y_train = getDataManually(os.path.join(\"dataset\", \"training_set\"))\n",
    "    x_test, x_test2, y_test = getDataManually(os.path.join(\"dataset\", \"test_set\"))\n",
    "    \n",
    "    x_train = numpy.array(x_train)\n",
    "    x_train = numpy.reshape(x_train, (len(x_train), 3, img_rows, img_cols))\n",
    "    x_train = x_train.astype(\"float64\")\n",
    "    x_train /= 255\n",
    "\n",
    "    x_test = numpy.array(x_test)\n",
    "    x_test = numpy.reshape(x_test, (len(x_test), 3, img_rows, img_cols))\n",
    "    x_test = x_test.astype(\"float64\")\n",
    "    x_train /= 255\n",
    "        \n",
    "    x_train2 = numpy.array(x_train2)\n",
    "    x_train2 = x_train2.astype(\"float64\")\n",
    "    x_train2 /= 10\n",
    "    \n",
    "    x_test2 = numpy.array(x_test2)\n",
    "    x_test2 = x_test2.astype(\"float64\")\n",
    "    x_test2 /= 10\n",
    "    \n",
    "    y_train = encodeAll(y_train)\n",
    "    y_test = encodeAll(y_test)\n",
    "    \n",
    "    return x_train, x_train2, y_train, x_test, x_test2, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pop_layer(model):\n",
    "    if not model.outputs:\n",
    "        raise Exception('Sequential model cannot be popped: model is empty.')\n",
    "\n",
    "    model.layers.pop()\n",
    "    if not model.layers:\n",
    "        model.outputs = []\n",
    "        model.inbound_nodes = []\n",
    "        model.outbound_nodes = []\n",
    "    else:\n",
    "        model.layers[-1].outbound_nodes = []\n",
    "        model.outputs = [model.layers[-1].output]\n",
    "    model.built = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#base_model = InceptionV3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "#print(base_model.summary())\n",
    "#Pop the last dense layer\n",
    "#base_model.layers.pop()\n",
    "#base_model.layers[-1].outbound_nodes = []\n",
    "#base_model.outputs = [base_model.layers[-1].output]\n",
    "#base_model.output = base_model.layers[-1].output\n",
    "\n",
    "#Add my layer[s]\n",
    "#output = base_model.output\n",
    "#output = Dense(128, name=\"1-dense\", activation='relu')(output)\n",
    "#image_model = Model(inputs = base_model.input, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Part 3 -> get the model\n",
    "def getModel():\n",
    "    max_caption_len = 3\n",
    "    vocab_size = 11\n",
    "\n",
    "    # first, let's define an image model that\n",
    "    # will encode pictures into 128-dimensional vectors.\n",
    "    # Get the InceptionV3 model\n",
    "    base_model = InceptionV3(include_top = True, weights = 'imagenet', input_tensor = None, input_shape = None, pooling = None, classes = 1000)\n",
    "    # Pop the last dense layer\n",
    "    base_model.layers.pop()\n",
    "    # Form a new model with just the layers we meed\n",
    "    filtered_base_model = Model(inputs = base_model.input, outputs = base_model.layers[-1].output)\n",
    "\n",
    "    # Add my layer[s]\n",
    "    output = filtered_base_model.output\n",
    "    output = Dense(128, name=\"1-dense\", activation='relu')(output)\n",
    "    output = RepeatVector(max_caption_len)(output)\n",
    "    image_model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    # next, let's define a RNN model that encodes sequences of words\n",
    "    # into sequences of 128-dimensional word vectors.\n",
    "    language_model = Sequential()\n",
    "    language_model.add(Embedding(vocab_size, 256, input_length=max_caption_len))\n",
    "    language_model.add(LSTM(output_dim=128, return_sequences=True))\n",
    "    language_model.add(TimeDistributed(Dense(128)))\n",
    "\n",
    "\n",
    "    # the output of both models will be tensors of shape (samples, max_caption_len, 128).\n",
    "    # let's concatenate these 2 vector sequences.\n",
    "    model = Sequential()\n",
    "    model.add(Merge([image_model, language_model], mode='concat', concat_axis=-1))\n",
    "    # let's encode this vector sequence into a single vector\n",
    "    model.add(LSTM(1024, return_sequences = True))\n",
    "    model.add(LSTM(1024, return_sequences = False))\n",
    "    \n",
    "    # which will be used to compute a probability\n",
    "    # distribution over what the next word in the caption should be!\n",
    "    model.add(Dense(vocab_size))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "    # \"images\" is a numpy float array of shape (num_samples, num_channels=3, width, height).\n",
    "    # \"captions\" is a numpy integer array of shape (num_samples, max_caption_len)\n",
    "    # containing word index sequences representing partial captions.\n",
    "    # \"next_words\" is a numpy float array of shape (num_samples, vocab_size)\n",
    "    # containing a categorical encoding (0s and 1s) of the next word in the corresponding\n",
    "    # partial caption.\n",
    "    #model.fit([images, partial_captions], next_words, batch_size=16, epochs=100)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Part 4 -> fit the model\n",
    "def fitModel(x_train, x_train2, y_train, x_test, x_test2, y_test, model):\n",
    "    filepath = \"12v4CNNLSTMModel-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "    tensorboard = TensorBoard(log_dir='./tensorboard', histogram_freq=2, batch_size=32, write_graph=True, write_grads=True, write_images=True, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    model.fit([x_train, x_train2], y_train, \n",
    "              batch_size= 1, \n",
    "              epochs = 2, \n",
    "              validation_data = ([x_test, x_test2], y_test),\n",
    "              callbacks = callbacks_list )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picture 3000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/556/131.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/src/keras/applications/inception_v3.py:365: UserWarning: You are using the TensorFlow backend, yet you are using the Theano image data format convention (`image_data_format=\"channels_first\"`). For best performance, set `image_data_format=\"channels_last\"` in your Keras config at ~/.keras/keras.json.\n",
      "  warnings.warn('You are using the TensorFlow backend, yet you '\n",
      "/opt/conda/lib/python3.5/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(units=128, return_sequences=True)`\n",
      "/opt/conda/lib/python3.5/site-packages/ipykernel_launcher.py:32: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_1 (Merge)              (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 3, 1024)           5246976   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 1024)              8392704   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 11)                11275     \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 11)                0         \n",
      "=================================================================\n",
      "Total params: 35,932,459\n",
      "Trainable params: 35,898,027\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n",
      "Final classifier summary:  None\n",
      "Train on 3600 samples, validate on 1800 samples\n",
      "Epoch 1/2\n",
      "3599/3600 [============================>.] - ETA: 0s - loss: 2.3504 - acc: 0.1148Epoch 00000: loss improved from inf to 2.35032, saving model to 12v4CNNLSTMModel-00-2.3503.hdf5\n",
      "3600/3600 [==============================] - 796s - loss: 2.3503 - acc: 0.1150 - val_loss: 2.3337 - val_acc: 0.1161\n",
      "Epoch 2/2\n",
      "2680/3600 [=====================>........] - ETA: 152s - loss: 2.3371 - acc: 0.0985"
     ]
    }
   ],
   "source": [
    "#Part 5 -> run everything\n",
    "x_train, x_train2, y_train, x_test, x_test2, y_test = getData()\n",
    "\n",
    "classifier = getModel()\n",
    "print(\"Final classifier summary: \", classifier.summary())\n",
    "fitModel(x_train, x_train2, y_train, x_test, x_test2, y_test, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train2[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train2[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test an image case\n",
    "x = get_im('/src/docker_shared/12Captcha/dataset/test_set/411/377.png')\n",
    "x = numpy.array(x)\n",
    "x = numpy.reshape(x, (1, 3, img_rows, img_cols))\n",
    "x = x.astype(\"float64\")\n",
    "\n",
    "x2 = numpy.array([[4,2, 10]])\n",
    "\n",
    "y = ['341']\n",
    "\n",
    "pred = classifier.predict([x,x2])\n",
    "print(\"Pred  : \", pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"nu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
