{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Merge\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import genfromtxt\n",
    "from keras.utils import np_utils\n",
    "import tensorflow\n",
    "import numpy\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import copy\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Part 1 -> defines\n",
    "img_channels, img_rows, img_cols = 1, 128, 128\n",
    "max_caption_len = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Part 2 -> get data\n",
    "def get_im(path):\n",
    "    # Load as grayscale\n",
    "    img = cv2.imread(path, 0)\n",
    "    # Reduce size\n",
    "    resized = cv2.resize(img, (img_cols, img_rows))\n",
    "    return resized\n",
    "\n",
    "\n",
    "def encode(str, num_rows):\n",
    "    \"\"\"\n",
    "    One hot encodes str\n",
    "    params: num_rows for keeping the num_rows the same\n",
    "    \"\"\"\n",
    "    \n",
    "    chars = '0123456789'\n",
    "    char_to_nr = dict( (ch, nr) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    nr_to_char = dict( (nr, ch) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    \n",
    "    #Matrice of zeros with the following shape [number_of_lines][max_different_chars_per_line]\n",
    "    x = np.zeros((num_rows, len(chars)))\n",
    "        \n",
    "    #Do the encoding\n",
    "    for i, ch in enumerate(str):\n",
    "        x[i, char_to_nr[ch]] = True\n",
    "        \n",
    "    return x    \n",
    "        \n",
    "def decode(x, calc_argmax = True):\n",
    "    \"\"\"\n",
    "    Decodes x and returns it\n",
    "    \"\"\"\n",
    "        \n",
    "    chars = '0123456789'\n",
    "    char_to_nr = dict( (ch, nr) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    nr_to_char = dict( (nr, ch) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    \n",
    "    if calc_argmax:\n",
    "        x = x.argmax(axis = -1)\n",
    "        \n",
    "    return ''.join(nr_to_char[x] for x in x)\n",
    "    \n",
    "def encodeAll(data):\n",
    "    chars = '0123456789'\n",
    "    MAX_LEN_Y = 1\n",
    "    \n",
    "    # [number_of_lines][total_different_chars_possible]\n",
    "    y = np.zeros( (len(data), len(chars)), dtype = np.bool )\n",
    "    \n",
    "    for i, line in enumerate(data):\n",
    "        y[i] = encode(line, MAX_LEN_Y)\n",
    "    \n",
    "    return y\n",
    "\n",
    "def pad(str, size):\n",
    "    newStr = copy.deepcopy(str)\n",
    "    while(len(newStr) < size):\n",
    "        newStr.append(0)\n",
    "        \n",
    "    return newStr\n",
    "\n",
    "def getDataManually(path):\n",
    "    X = []\n",
    "    X2 = []\n",
    "    y = []\n",
    "    \n",
    "\n",
    "    for dir in os.listdir(path):\n",
    "        crtPath = os.path.join(path, dir, \"*.png\")\n",
    "        \n",
    "        files = glob.glob(crtPath)\n",
    "        for fl in files:\n",
    "             # X\n",
    "             fl = os.path.join(cwd, fl)\n",
    "             img = get_im(fl)\n",
    "            \n",
    "             # Y\n",
    "             crtSeq = ''\n",
    "             crtSeqList = []\n",
    "             \n",
    "             X.append(img)\n",
    "             X2.append( pad(crtSeqList, 3) )\n",
    "             y.append( str(dir[0]) )\n",
    "                \n",
    "             for i in range( len(str(dir)) - 1 ):\n",
    "                    crtSeq += dir[i]\n",
    "                    crtSeqList.append( int(dir[i]) )\n",
    "                    \n",
    "                    X.append(img)\n",
    "                    X2.append( pad(crtSeqList, 3) )\n",
    "                    y.append( str(dir[i + 1]) )\n",
    "                    \n",
    "             if len(X) % 1000 == 0:\n",
    "                 print(\"Picture \" + str(len(X)) + \" added from path: \", fl)\n",
    "    \n",
    "    return X, X2, y\n",
    "\n",
    "def getData():\n",
    "    x_train, x_train2, y_train = getDataManually(os.path.join(\"dataset\", \"training_set\"))\n",
    "    x_test, x_test2, y_test = getDataManually(os.path.join(\"dataset\", \"test_set\"))\n",
    "    \n",
    "    x_train = numpy.array(x_train)\n",
    "    x_train = numpy.reshape(x_train, (len(x_train), 1, img_rows, img_cols))\n",
    "    x_train = x_train.astype(\"float32\")\n",
    "    x_train /= 255\n",
    "\n",
    "    x_test = numpy.array(x_test)\n",
    "    x_test = numpy.reshape(x_test, (len(x_test), 1, img_rows, img_cols))\n",
    "    x_test = x_test.astype(\"float32\")\n",
    "    x_train /= 255\n",
    "        \n",
    "    x_train2 = numpy.array(x_train2)\n",
    "    x_test2 = numpy.array(x_test2)\n",
    "\n",
    "    y_train = encodeAll(y_train)\n",
    "    y_test = encodeAll(y_test)\n",
    "    \n",
    "    return x_train, x_train2, y_train, x_test, x_test2, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Part 3 -> get the model\n",
    "def getModel():\n",
    "    max_caption_len = 3\n",
    "    vocab_size = 10\n",
    "\n",
    "    # first, let's define an image model that\n",
    "    # will encode pictures into 128-dimensional vectors.\n",
    "    # it should be initialized with pre-trained weights.\n",
    "    image_model = Sequential()\n",
    "    \n",
    "    #ENCODER PART\n",
    "    image_model.add(Conv2D(32, (3, 3), padding = 'valid', input_shape=(img_channels, img_rows, img_cols), name=\"1-conv\"))\n",
    "    image_model.add(Activation('relu'))\n",
    "    image_model.add(Conv2D(32, (3, 3), padding = 'valid', name=\"2-conv\"))\n",
    "    image_model.add(Activation('relu'))\n",
    "    image_model.add(MaxPooling2D(pool_size=(2, 2), name=\"1-pooling\"))\n",
    "\n",
    "    image_model.add(Conv2D(64, (3, 3), padding = 'valid', name=\"3-conv\"))\n",
    "    image_model.add(Activation('relu'))\n",
    "    image_model.add(Conv2D(64, (3, 3), padding = 'valid', name=\"4-conv\"))\n",
    "    image_model.add(Activation('relu'))\n",
    "    image_model.add(MaxPooling2D(pool_size=(2, 2), name=\"2-pooling\"))\n",
    "    \n",
    "    image_model.add(Conv2D(128, (3, 3), padding='valid', name=\"5-conv\"))\n",
    "    image_model.add(Activation('relu'))\n",
    "    image_model.add(Conv2D(128, (3, 3), padding='valid', name=\"6-conv\"))\n",
    "    image_model.add(Activation('relu'))\n",
    "    \n",
    "    image_model.add(Flatten())\n",
    "    image_model.add(Dense(128, name=\"1-dense\"))\n",
    "    image_model.add(Activation('relu'))\n",
    "    #Decoder part\n",
    "        \n",
    "    image_model.add( Dense(25*25*128) )\n",
    "    image_model.add( Activation('relu'))\n",
    "    image_model.add( Reshape( (128, 25, 25)) )\n",
    "    \n",
    "    image_model.add(Conv2DTranspose(128, (3, 3), padding='valid'))\n",
    "    image_model.add(Activation('relu'))\n",
    "    image_model.add(Conv2DTranspose(128, (3, 3)))\n",
    "    image_model.add(Activation('relu'))\n",
    "    \n",
    "    image_model.add( UpSampling2D((2, 2)) )\n",
    "    image_model.add( Conv2DTranspose(64, (3, 3), padding='valid') ) \n",
    "    image_model.add( Activation('relu') )\n",
    "    image_model.add( Conv2DTranspose(64, (3, 3), padding='valid') )\n",
    "    image_model.add( Activation('relu') )\n",
    "    image_model.add( UpSampling2D((2, 2)) )\n",
    "        \n",
    "\n",
    "    image_model.add( Conv2DTranspose(32, (3, 3), padding='valid') )\n",
    "    image_model.add( Activation('relu') )\n",
    "    image_model.add( Conv2DTranspose(32, (3, 3), padding='valid') )\n",
    "    image_model.add( Activation('relu') )\n",
    "    \n",
    "    image_model.add( Conv2DTranspose(1, (3, 3), padding='same') )\n",
    "    image_model.add( Activation('relu') )\n",
    "    \n",
    "    \n",
    "    image_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "    # \"images\" is a numpy float array of shape (num_samples, num_channels=3, width, height).\n",
    "    # \"captions\" is a numpy integer array of shape (num_samples, max_caption_len)\n",
    "    # containing word index sequences representing partial captions.\n",
    "    # \"next_words\" is a numpy float array of shape (num_samples, vocab_size)\n",
    "    # containing a categorical encoding (0s and 1s) of the next word in the corresponding\n",
    "    # partial caption.\n",
    "    #model.fit([images, partial_captions], next_words, batch_size=16, epochs=100)\n",
    "\n",
    "    return image_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Part 4 -> fit the model\n",
    "def fitModel(x_train, x_train2, y_train, x_test, x_test2, y_test, model):\n",
    "    filepath = \"12v4CNNLSTMModel-TrainCNNWeights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "    tensorboard = TensorBoard(log_dir='./tensorboard', histogram_freq=2, batch_size=32, write_graph=True, write_grads=True, write_images=True, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    model.fit(x_train, x_train, \n",
    "              batch_size=16, \n",
    "              epochs=75, \n",
    "              validation_data = (x_test, x_test),\n",
    "              callbacks = callbacks_list )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picture 3000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/512/81572.png\n",
      "Picture 6000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/885/37140.png\n",
      "Picture 9000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/287/4774.png\n",
      "Picture 12000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/578/29239.png\n",
      "Picture 15000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/534/9519.png\n",
      "Picture 18000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/820/5972.png\n",
      "Picture 21000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/922/78248.png\n",
      "Picture 24000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/176/64167.png\n",
      "Picture 27000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/710/83730.png\n",
      "Picture 30000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/599/32501.png\n",
      "Picture 33000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/649/22587.png\n",
      "Picture 36000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/715/79842.png\n",
      "Picture 39000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/866/47031.png\n",
      "Picture 42000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/642/5996.png\n",
      "Picture 45000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/522/56264.png\n",
      "Picture 48000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/793/94139.png\n",
      "Picture 51000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/757/36863.png\n",
      "Picture 54000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/307/42804.png\n",
      "Picture 57000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/485/53607.png\n",
      "Picture 60000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/372/81939.png\n",
      "Picture 63000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/686/38511.png\n",
      "Picture 66000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/351/13956.png\n",
      "Picture 69000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/591/13592.png\n",
      "Picture 72000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/274/98000.png\n",
      "Picture 75000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/579/34293.png\n",
      "Picture 78000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/519/54261.png\n",
      "Picture 81000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/993/52901.png\n",
      "Picture 84000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/263/60415.png\n",
      "Picture 87000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/312/50372.png\n",
      "Picture 90000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/136/93007.png\n",
      "Picture 93000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/256/15378.png\n",
      "Picture 96000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/912/92471.png\n",
      "Picture 99000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/992/32025.png\n",
      "Picture 102000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/525/52867.png\n",
      "Picture 105000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/338/96809.png\n",
      "Picture 108000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/987/66495.png\n",
      "Picture 111000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/621/44072.png\n",
      "Picture 114000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/389/74018.png\n",
      "Picture 117000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/805/50481.png\n",
      "Picture 120000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/722/43334.png\n",
      "Picture 123000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/353/94345.png\n",
      "Picture 126000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/290/56718.png\n",
      "Picture 129000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/972/56093.png\n",
      "Picture 132000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/613/15356.png\n",
      "Picture 135000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/367/60882.png\n",
      "Picture 138000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/734/38859.png\n",
      "Picture 141000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/123/5036.png\n",
      "Picture 144000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/863/69827.png\n",
      "Picture 147000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/540/20110.png\n",
      "Picture 150000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/983/71023.png\n",
      "Picture 153000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/267/62199.png\n",
      "Picture 156000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/162/11915.png\n",
      "Picture 159000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/970/98985.png\n",
      "Picture 162000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/974/12103.png\n",
      "Picture 165000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/633/47667.png\n",
      "Picture 168000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/395/94718.png\n",
      "Picture 171000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/960/13873.png\n",
      "Picture 174000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/237/99379.png\n",
      "Picture 177000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/461/82478.png\n",
      "Picture 180000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/652/48190.png\n",
      "Picture 183000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/536/57699.png\n",
      "Picture 186000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/843/76504.png\n",
      "Picture 189000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/949/1998.png\n",
      "Picture 192000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/385/50770.png\n",
      "Picture 195000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/116/44358.png\n",
      "Picture 198000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/746/60320.png\n",
      "Picture 201000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/514/48212.png\n",
      "Picture 204000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/713/30109.png\n",
      "Picture 207000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/600/83790.png\n",
      "Picture 210000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/138/4686.png\n",
      "Picture 213000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/213/95118.png\n",
      "Picture 216000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/296/67120.png\n",
      "Picture 219000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/216/58902.png\n",
      "Picture 222000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/544/57871.png\n",
      "Picture 225000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/173/69962.png\n",
      "Picture 228000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/676/22655.png\n",
      "Picture 231000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/466/30685.png\n",
      "Picture 234000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/920/9092.png\n",
      "Picture 237000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/266/90760.png\n",
      "Picture 240000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/748/51060.png\n",
      "Picture 243000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/381/58600.png\n",
      "Picture 246000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/753/58122.png\n",
      "Picture 249000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/335/22375.png\n",
      "Picture 252000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/238/30947.png\n",
      "Picture 255000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/516/21920.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picture 258000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/603/8771.png\n",
      "Picture 261000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/593/26779.png\n",
      "Picture 264000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/493/96511.png\n",
      "Picture 267000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/380/39490.png\n",
      "Picture 270000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/980/89441.png\n",
      "Picture 273000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/831/69149.png\n",
      "Picture 276000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/396/96811.png\n",
      "Picture 279000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/874/28803.png\n",
      "Picture 282000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/484/6090.png\n",
      "Picture 285000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/853/52010.png\n",
      "Picture 288000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/759/48040.png\n",
      "Picture 291000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/674/73519.png\n",
      "Picture 294000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/978/80988.png\n",
      "Picture 297000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/657/59042.png\n",
      "Picture 300000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/732/39462.png\n",
      "Picture 3000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/879/17640.png\n",
      "Picture 6000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/578/39915.png\n",
      "Picture 9000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/392/12442.png\n",
      "Picture 12000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/733/30289.png\n",
      "Picture 15000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/558/40740.png\n",
      "Picture 18000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/701/14022.png\n",
      "Picture 21000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/526/7637.png\n",
      "Picture 24000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/793/15222.png\n",
      "Picture 27000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/307/17839.png\n",
      "Picture 30000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/372/32625.png\n",
      "Picture 33000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/861/31959.png\n",
      "Picture 36000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/274/31150.png\n",
      "Picture 39000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/519/40475.png\n",
      "Picture 42000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/528/14410.png\n",
      "Picture 45000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/498/39352.png\n",
      "Picture 48000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/720/47405.png\n",
      "Picture 51000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/142/36227.png\n",
      "Picture 54000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/904/36439.png\n",
      "Picture 57000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/389/38428.png\n",
      "Picture 60000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/878/46684.png\n",
      "Picture 63000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/290/45131.png\n",
      "Picture 66000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/613/21054.png\n",
      "Picture 69000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/734/28718.png\n",
      "Picture 72000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/641/47994.png\n",
      "Picture 75000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/724/43976.png\n",
      "Picture 78000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/162/3945.png\n",
      "Picture 81000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/823/6781.png\n",
      "Picture 84000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/395/10600.png\n",
      "Picture 87000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/237/9178.png\n",
      "Picture 90000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/652/3760.png\n",
      "Picture 93000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/884/39491.png\n",
      "Picture 96000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/160/15457.png\n",
      "Picture 99000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/746/18190.png\n",
      "Picture 102000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/760/8856.png\n",
      "Picture 105000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/158/23835.png\n",
      "Picture 108000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/663/49602.png\n",
      "Picture 111000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/544/25407.png\n",
      "Picture 114000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/676/27752.png\n",
      "Picture 117000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/400/46272.png\n",
      "Picture 120000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/437/8857.png\n",
      "Picture 123000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/753/24753.png\n",
      "Picture 126000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/238/5244.png\n",
      "Picture 129000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/570/34455.png\n",
      "Picture 132000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/493/41588.png\n",
      "Picture 135000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/980/173.png\n",
      "Picture 138000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/559/32993.png\n",
      "Picture 141000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/484/35584.png\n",
      "Picture 144000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/759/37897.png\n",
      "Picture 147000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/978/47525.png\n",
      "Picture 150000 added from path:  /src/docker_shared/12Captcha/dataset/test_set/732/48178.png\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "1-conv (Conv2D)              (None, 32, 126, 126)      320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 126, 126)      0         \n",
      "_________________________________________________________________\n",
      "2-conv (Conv2D)              (None, 32, 124, 124)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 124, 124)      0         \n",
      "_________________________________________________________________\n",
      "1-pooling (MaxPooling2D)     (None, 32, 62, 62)        0         \n",
      "_________________________________________________________________\n",
      "3-conv (Conv2D)              (None, 64, 60, 60)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64, 60, 60)        0         \n",
      "_________________________________________________________________\n",
      "4-conv (Conv2D)              (None, 64, 58, 58)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64, 58, 58)        0         \n",
      "_________________________________________________________________\n",
      "2-pooling (MaxPooling2D)     (None, 64, 29, 29)        0         \n",
      "_________________________________________________________________\n",
      "5-conv (Conv2D)              (None, 128, 27, 27)       73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128, 27, 27)       0         \n",
      "_________________________________________________________________\n",
      "6-conv (Conv2D)              (None, 128, 25, 25)       147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128, 25, 25)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 80000)             0         \n",
      "_________________________________________________________________\n",
      "1-dense (Dense)              (None, 128)               10240128  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 80000)             10320000  \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 80000)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 128, 25, 25)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 128, 27, 27)       147584    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 128, 27, 27)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 128, 29, 29)       147584    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 128, 29, 29)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 128, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 64, 60, 60)        73792     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 64, 60, 60)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 64, 62, 62)        36928     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 64, 62, 62)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 64, 124, 124)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 32, 126, 126)      18464     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32, 126, 126)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 32, 128, 128)      9248      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 32, 128, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 1, 128, 128)       289       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 1, 128, 128)       0         \n",
      "=================================================================\n",
      "Total params: 21,280,449\n",
      "Trainable params: 21,280,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300000 samples, validate on 150000 samples\n",
      "Epoch 1/75\n",
      "182352/300000 [=================>............] - ETA: 1289s - loss: 2.2152 - acc: 0.3247"
     ]
    }
   ],
   "source": [
    "#Part 5 -> run everything\n",
    "x_train, x_train2, y_train, x_test, x_test2, y_test = getData()\n",
    "\n",
    "classifier = getModel()\n",
    "classifier.summary()\n",
    "fitModel(x_train, x_train2, y_train, x_test, x_test2, y_test, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(x_train2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(x_train2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(x_train2[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(y_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(x_train2[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test an image case\n",
    "x = get_im('/docker_shared/12Captcha/dataset/test_set/672/427.png')\n",
    "x = numpy.array(x)\n",
    "x = numpy.reshape(x, (1, 1, img_rows, img_cols))\n",
    "x = x.astype(\"float64\")\n",
    "\n",
    "x2 = numpy.array([[1,2,3]])\n",
    "\n",
    "y = ['341']\n",
    "\n",
    "pred = classifier.predict([x,x2])\n",
    "print(\"Pred  : \", pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"nu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
