{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Merge\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import genfromtxt\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import copy\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Part 1 -> defines\n",
    "img_channels, img_rows, img_cols = 1, 128, 128\n",
    "max_caption_len = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Part 2 -> get data\n",
    "def get_im(path):\n",
    "    # Load as grayscale\n",
    "    img = cv2.imread(path, 0)\n",
    "    # Reduce size\n",
    "    resized = cv2.resize(img, (img_cols, img_rows))\n",
    "    return resized\n",
    "\n",
    "\n",
    "def encode(str, num_rows):\n",
    "    \"\"\"\n",
    "    One hot encodes str\n",
    "    params: num_rows for keeping the num_rows the same\n",
    "    \"\"\"\n",
    "    \n",
    "    chars = '0123456789'\n",
    "    char_to_nr = dict( (ch, nr) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    nr_to_char = dict( (nr, ch) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    \n",
    "    #Matrice of zeros with the following shape [number_of_lines][max_different_chars_per_line]\n",
    "    x = np.zeros((num_rows, len(chars)))\n",
    "        \n",
    "    #Do the encoding\n",
    "    for i, ch in enumerate(str):\n",
    "        x[i, char_to_nr[ch]] = True\n",
    "        \n",
    "    return x    \n",
    "        \n",
    "def decode(x, calc_argmax = True):\n",
    "    \"\"\"\n",
    "    Decodes x and returns it\n",
    "    \"\"\"\n",
    "        \n",
    "    chars = '0123456789'\n",
    "    char_to_nr = dict( (ch, nr) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    nr_to_char = dict( (nr, ch) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    \n",
    "    if calc_argmax:\n",
    "        x = x.argmax(axis = -1)\n",
    "        \n",
    "    return ''.join(nr_to_char[x] for x in x)\n",
    "    \n",
    "def encodeAll(data):\n",
    "    chars = '0123456789'\n",
    "    MAX_LEN_Y = 1\n",
    "    \n",
    "    # [number_of_lines][total_different_chars_possible]\n",
    "    y = np.zeros( (len(data), len(chars)), dtype = np.bool )\n",
    "    \n",
    "    for i, line in enumerate(data):\n",
    "        y[i] = encode(line, MAX_LEN_Y)\n",
    "    \n",
    "    return y\n",
    "\n",
    "def pad(str, size):\n",
    "    newStr = copy.deepcopy(str)\n",
    "    while(len(newStr) < size):\n",
    "        newStr.append(0)\n",
    "        \n",
    "    return newStr\n",
    "\n",
    "def getDataManually(path):\n",
    "    X = []\n",
    "    X2 = []\n",
    "    y = []\n",
    "    \n",
    "\n",
    "    for dir in os.listdir(path):\n",
    "        crtPath = os.path.join(path, dir, \"*.png\")\n",
    "        \n",
    "        files = glob.glob(crtPath)\n",
    "        for fl in files:\n",
    "             # X\n",
    "             fl = os.path.join(cwd, fl)\n",
    "             img = get_im(fl)\n",
    "            \n",
    "             # Y\n",
    "             crtSeq = ''\n",
    "             crtSeqList = []\n",
    "             \n",
    "             X.append(img)\n",
    "             X2.append( pad(crtSeqList, 3) )\n",
    "             y.append( str(dir[0]) )\n",
    "                \n",
    "             for i in range( len(str(dir)) - 1 ):\n",
    "                    crtSeq += dir[i]\n",
    "                    crtSeqList.append( int(dir[i]) )\n",
    "                    \n",
    "                    X.append(img)\n",
    "                    X2.append( pad(crtSeqList, 3) )\n",
    "                    y.append( str(dir[i + 1]) )\n",
    "                    \n",
    "             if len(X) % 1000 == 0:\n",
    "                 print(\"Picture \" + str(len(X)) + \" added from path: \", fl)\n",
    "    \n",
    "    return X, X2, y\n",
    "\n",
    "def getData():\n",
    "    x_train, x_train2, y_train = getDataManually(os.path.join(\"dataset\", \"training_set\"))\n",
    "    x_test, x_test2, y_test = getDataManually(os.path.join(\"dataset\", \"test_set\"))\n",
    "    \n",
    "    x_train = numpy.array(x_train)\n",
    "    x_train = numpy.reshape(x_train, (len(x_train), 1, img_rows, img_cols))\n",
    "    x_train = x_train.astype(\"float32\")\n",
    "    x_train /= 255\n",
    "\n",
    "    x_test = numpy.array(x_test)\n",
    "    x_test = numpy.reshape(x_test, (len(x_test), 1, img_rows, img_cols))\n",
    "    x_test = x_test.astype(\"float32\")\n",
    "    x_train /= 255\n",
    "        \n",
    "    x_train2 = numpy.array(x_train2)\n",
    "    x_test2 = numpy.array(x_test2)\n",
    "\n",
    "    y_train = encodeAll(y_train)\n",
    "    y_test = encodeAll(y_test)\n",
    "    \n",
    "    return x_train, x_train2, y_train, x_test, x_test2, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Part 3 -> get the model\n",
    "def getModel():\n",
    "    max_caption_len = 3\n",
    "    vocab_size = 10\n",
    "\n",
    "    # first, let's define an image model that\n",
    "    # will encode pictures into 128-dimensional vectors.\n",
    "    # it should be initialized with pre-trained weights.\n",
    "    image_model = Sequential()\n",
    "    image_model.add(Conv2D(32, (3, 3), padding = 'valid', input_shape=(img_channels, img_rows, img_cols)))\n",
    "    image_model.add(Activation('relu'))\n",
    "    image_model.add(Conv2D(32, (3, 3), padding = 'valid'))\n",
    "    image_model.add(Activation('relu'))\n",
    "    image_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    image_model.add(Conv2D(64, (3, 3), padding = 'valid'))\n",
    "    image_model.add(Activation('relu'))\n",
    "    image_model.add(Conv2D(64, (3, 3), padding = 'valid'))\n",
    "    image_model.add(Activation('relu'))\n",
    "    image_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    image_model.add(Conv2D(128, (3, 3), padding='valid'))\n",
    "    image_model.add(Activation('relu'))\n",
    "    image_model.add(Conv2D(128, (3, 3)))\n",
    "    image_model.add(Activation('relu'))\n",
    "\n",
    "    image_model.add(Flatten())\n",
    "    image_model.add(Dense(128))\n",
    "\n",
    "    # let's load the weights from a save file.\n",
    "    #image_model.load_weights('weight_file.h5')\n",
    "\n",
    "    # next, let's define a RNN model that encodes sequences of words\n",
    "    # into sequences of 128-dimensional word vectors.\n",
    "    language_model = Sequential()\n",
    "    language_model.add(Embedding(vocab_size, 256, input_length=max_caption_len))\n",
    "    language_model.add(GRU(output_dim=128, return_sequences=True))\n",
    "    language_model.add(TimeDistributed(Dense(128)))\n",
    "\n",
    "    # let's repeat the image vector to turn it into a sequence.\n",
    "    image_model.add(RepeatVector(max_caption_len))\n",
    "\n",
    "    # the output of both models will be tensors of shape (samples, max_caption_len, 128).\n",
    "    # let's concatenate these 2 vector sequences.\n",
    "    model = Sequential()\n",
    "    model.add(Merge([image_model, language_model], mode='concat', concat_axis=-1))\n",
    "    # let's encode this vector sequence into a single vector\n",
    "    model.add(GRU(512, return_sequences=False))\n",
    "    model.add(Dense(1024, ))\n",
    "    # which will be used to compute a probability\n",
    "    # distribution over what the next word in the caption should be!\n",
    "    model.add(Dense(vocab_size))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "    # \"images\" is a numpy float array of shape (num_samples, num_channels=3, width, height).\n",
    "    # \"captions\" is a numpy integer array of shape (num_samples, max_caption_len)\n",
    "    # containing word index sequences representing partial captions.\n",
    "    # \"next_words\" is a numpy float array of shape (num_samples, vocab_size)\n",
    "    # containing a categorical encoding (0s and 1s) of the next word in the corresponding\n",
    "    # partial caption.\n",
    "    #model.fit([images, partial_captions], next_words, batch_size=16, epochs=100)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Part 4 -> fit the model\n",
    "def fitModel(x_train, x_train2, y_train, x_test, x_test2, y_test, model):\n",
    "    filepath = \"12v4CNNLSTMModel-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "    tensorboard = TensorBoard(log_dir='./tensorboard', histogram_freq=2, batch_size=32, write_graph=True, write_grads=True, write_images=True, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "    callbacks_list = [tensorboard]\n",
    "\n",
    "    model.fit([x_train, x_train2], y_train, \n",
    "              batch_size=16, \n",
    "              epochs=4, \n",
    "              validation_data = ([x_test, x_test2], y_test),\n",
    "              callbacks = callbacks_list )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picture 3000 added from path:  /src/docker_shared/12Captcha/dataset/training_set/556/131.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/ipykernel_launcher.py:38: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(return_sequences=True, units=128)`\n",
      "/opt/conda/lib/python3.5/site-packages/ipykernel_launcher.py:47: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_1 (Merge)              (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 512)               1181184   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                10250     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 5,579,114\n",
      "Trainable params: 5,579,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3600 samples, validate on 1800 samples\n",
      "Epoch 1/4\n",
      "3600/3600 [==============================] - 556s - loss: 2.9857 - acc: 0.0975 - val_loss: 2.8327 - val_acc: 0.1150\n",
      "Epoch 2/4\n",
      "3600/3600 [==============================] - 507s - loss: 2.5031 - acc: 0.0969 - val_loss: 2.4463 - val_acc: 0.0978\n",
      "Epoch 3/4\n",
      "3600/3600 [==============================] - 621s - loss: 2.3944 - acc: 0.1064 - val_loss: 2.3086 - val_acc: 0.1150\n",
      "Epoch 4/4\n",
      " 432/3600 [==>...........................] - ETA: 380s - loss: 2.3292 - acc: 0.1019"
     ]
    }
   ],
   "source": [
    "#Part 5 -> run everything\n",
    "x_train, x_train2, y_train, x_test, x_test2, y_test = getData()\n",
    "\n",
    "classifier = getModel()\n",
    "classifier.summary()\n",
    "fitModel(x_train, x_train2, y_train, x_test, x_test2, y_test, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train2[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train2[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred  :  [ 0.09362856  0.09199297  0.08601591  0.11848346  0.13384528  0.09528937\n",
      "  0.11850605  0.09794832  0.0868976   0.07739241]\n"
     ]
    }
   ],
   "source": [
    "#Test an image case\n",
    "x = get_im('/src/docker_shared/12Captcha/dataset/test_set/411/377.png')\n",
    "x = numpy.array(x)\n",
    "x = numpy.reshape(x, (1, 1, img_rows, img_cols))\n",
    "x = x.astype(\"float64\")\n",
    "\n",
    "x2 = numpy.array([[4,2, 3]])\n",
    "\n",
    "y = ['341']\n",
    "\n",
    "pred = classifier.predict([x,x2])\n",
    "print(\"Pred  : \", pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nu\n"
     ]
    }
   ],
   "source": [
    "print(\"nu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.client.session.Session object at 0x7fd5bfde25f8>\n"
     ]
    }
   ],
   "source": [
    "print(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
