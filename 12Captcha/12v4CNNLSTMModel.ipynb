{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Merge\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import genfromtxt\n",
    "from keras.utils import np_utils\n",
    "import tensorflow\n",
    "import numpy\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import copy\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Part 1 -> defines\n",
    "img_channels, img_rows, img_cols = 1, 128, 128\n",
    "max_caption_len = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Part 2 -> get data\n",
    "def get_im(path):\n",
    "    # Load as grayscale\n",
    "    img = cv2.imread(path, 0)\n",
    "    # Reduce size\n",
    "    resized = cv2.resize(img, (img_cols, img_rows))\n",
    "    return resized\n",
    "\n",
    "\n",
    "def encode(str, num_rows):\n",
    "    \"\"\"\n",
    "    One hot encodes str\n",
    "    params: num_rows for keeping the num_rows the same\n",
    "    \"\"\"\n",
    "    \n",
    "    chars = '0123456789'\n",
    "    char_to_nr = dict( (ch, nr) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    nr_to_char = dict( (nr, ch) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    \n",
    "    #Matrice of zeros with the following shape [number_of_lines][max_different_chars_per_line]\n",
    "    x = np.zeros((num_rows, len(chars)))\n",
    "        \n",
    "    #Do the encoding\n",
    "    for i, ch in enumerate(str):\n",
    "        x[i, char_to_nr[ch]] = True\n",
    "        \n",
    "    return x    \n",
    "        \n",
    "def decode(x, calc_argmax = True):\n",
    "    \"\"\"\n",
    "    Decodes x and returns it\n",
    "    \"\"\"\n",
    "        \n",
    "    chars = '0123456789'\n",
    "    char_to_nr = dict( (ch, nr) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    nr_to_char = dict( (nr, ch) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    \n",
    "    if calc_argmax:\n",
    "        x = x.argmax(axis = -1)\n",
    "        \n",
    "    return ''.join(nr_to_char[x] for x in x)\n",
    "    \n",
    "def encodeAll(data):\n",
    "    chars = '0123456789'\n",
    "    MAX_LEN_Y = 1\n",
    "    \n",
    "    # [number_of_lines][total_different_chars_possible]\n",
    "    y = np.zeros( (len(data), len(chars)), dtype = np.bool )\n",
    "    \n",
    "    for i, line in enumerate(data):\n",
    "        y[i] = encode(line, MAX_LEN_Y)\n",
    "    \n",
    "    return y\n",
    "\n",
    "def pad(str, size):\n",
    "    newStr = copy.deepcopy(str)\n",
    "    while(len(newStr) < size):\n",
    "        newStr.append(0)\n",
    "        \n",
    "    return newStr\n",
    "\n",
    "def getDataManually(path):\n",
    "    X = []\n",
    "    X2 = []\n",
    "    y = []\n",
    "    \n",
    "\n",
    "    for dir in os.listdir(path):\n",
    "        crtPath = os.path.join(path, dir, \"*.png\")\n",
    "        \n",
    "        files = glob.glob(crtPath)\n",
    "        for fl in files:\n",
    "             # X\n",
    "             fl = os.path.join(cwd, fl)\n",
    "             img = get_im(fl)\n",
    "            \n",
    "             # Y\n",
    "             crtSeq = ''\n",
    "             crtSeqList = []\n",
    "             \n",
    "             X.append(img)\n",
    "             X2.append( pad(crtSeqList, 3) )\n",
    "             y.append( str(dir[0]) )\n",
    "                \n",
    "             for i in range( len(str(dir)) - 1 ):\n",
    "                    crtSeq += dir[i]\n",
    "                    crtSeqList.append( int(dir[i]) )\n",
    "                    \n",
    "                    X.append(img)\n",
    "                    X2.append( pad(crtSeqList, 3) )\n",
    "                    y.append( str(dir[i + 1]) )\n",
    "                    \n",
    "             if len(X) % 1000 == 0:\n",
    "                 print(\"Picture \" + str(len(X)) + \" added from path: \", fl)\n",
    "    \n",
    "    return X, X2, y\n",
    "\n",
    "def getData():\n",
    "    x_train, x_train2, y_train = getDataManually(os.path.join(\"dataset\", \"training_set\"))\n",
    "    x_test, x_test2, y_test = getDataManually(os.path.join(\"dataset\", \"test_set\"))\n",
    "    \n",
    "    x_train = numpy.array(x_train)\n",
    "    x_train = numpy.reshape(x_train, (len(x_train), 1, img_rows, img_cols))\n",
    "    x_train = x_train.astype(\"float64\")\n",
    "\n",
    "    x_test = numpy.array(x_test)\n",
    "    x_test = numpy.reshape(x_test, (len(x_test), 1, img_rows, img_cols))\n",
    "    x_test = x_test.astype(\"float64\")\n",
    "\n",
    "    x_train2 = numpy.array(x_train2)\n",
    "    x_test2 = numpy.array(x_test2)\n",
    "\n",
    "    y_train = encodeAll(y_train)\n",
    "    y_test = encodeAll(y_test)\n",
    "    \n",
    "    return x_train, x_train2, y_train, x_test, x_test2, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Part 3 -> get the model\n",
    "def getModel():\n",
    "    max_caption_len = 3\n",
    "    vocab_size = 10\n",
    "\n",
    "    # first, let's define an image model that\n",
    "    # will encode pictures into 128-dimensional vectors.\n",
    "    # it should be initialized with pre-trained weights.\n",
    "    image_model = Sequential()\n",
    "    image_model.add(Convolution2D(32, 3, 3, border_mode='valid', input_shape=(img_channels, img_rows, img_cols)))\n",
    "    image_model.add(Activation('relu'))\n",
    "    image_model.add(Convolution2D(32, 3, 3))\n",
    "    image_model.add(Activation('relu'))\n",
    "    image_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    image_model.add(Convolution2D(64, 3, 3, border_mode='valid'))\n",
    "    image_model.add(Activation('relu'))\n",
    "    image_model.add(Convolution2D(64, 3, 3))\n",
    "    image_model.add(Activation('relu'))\n",
    "    image_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    image_model.add(Flatten())\n",
    "    image_model.add(Dense(128))\n",
    "\n",
    "    # let's load the weights from a save file.\n",
    "    #image_model.load_weights('weight_file.h5')\n",
    "\n",
    "    # next, let's define a RNN model that encodes sequences of words\n",
    "    # into sequences of 128-dimensional word vectors.\n",
    "    language_model = Sequential()\n",
    "    language_model.add(Embedding(vocab_size, 256, input_length=max_caption_len))\n",
    "    language_model.add(GRU(output_dim=128, return_sequences=True))\n",
    "    language_model.add(TimeDistributed(Dense(128)))\n",
    "\n",
    "    # let's repeat the image vector to turn it into a sequence.\n",
    "    image_model.add(RepeatVector(max_caption_len))\n",
    "\n",
    "    # the output of both models will be tensors of shape (samples, max_caption_len, 128).\n",
    "    # let's concatenate these 2 vector sequences.\n",
    "    model = Sequential()\n",
    "    model.add(Merge([image_model, language_model], mode='concat', concat_axis=-1))\n",
    "    # let's encode this vector sequence into a single vector\n",
    "    model.add(GRU(256, return_sequences=False))\n",
    "    # which will be used to compute a probability\n",
    "    # distribution over what the next word in the caption should be!\n",
    "    model.add(Dense(vocab_size))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "    # \"images\" is a numpy float array of shape (num_samples, num_channels=3, width, height).\n",
    "    # \"captions\" is a numpy integer array of shape (num_samples, max_caption_len)\n",
    "    # containing word index sequences representing partial captions.\n",
    "    # \"next_words\" is a numpy float array of shape (num_samples, vocab_size)\n",
    "    # containing a categorical encoding (0s and 1s) of the next word in the corresponding\n",
    "    # partial caption.\n",
    "    #model.fit([images, partial_captions], next_words, batch_size=16, epochs=100)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Part 4 -> fit the model\n",
    "def fitModel(x_train, x_train2, y_train, x_test, x_test2, y_test, model):\n",
    "    filepath = \"12v4CNNLSTMModel-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    model.fit([x_train, x_train2], y_train, \n",
    "              batch_size=16, \n",
    "              nb_epoch=15, \n",
    "              validation_data = ([x_test, x_test2], y_test),\n",
    "              callbacks = callbacks_list )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Picture 3000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/556/131.png')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py:368: UserWarning: The `regularizers` property of layers/models is deprecated. Regularization losses are now managed via the `losses` layer/model property.\n",
      "  warnings.warn('The `regularizers` property of '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 32, 126, 126)  320                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 32, 126, 126)  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 32, 124, 124)  9248                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 32, 124, 124)  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 32, 62, 62)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 64, 60, 60)    18496                                        \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 64, 60, 60)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 64, 58, 58)    36928                                        \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 64, 58, 58)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 64, 29, 29)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 53824)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           6889600                                      \n",
      "____________________________________________________________________________________________________\n",
      "repeatvector_1 (RepeatVector)    (None, 3, 128)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 3, 256)        2560                                         \n",
      "____________________________________________________________________________________________________\n",
      "gru_1 (GRU)                      (None, 3, 128)        147840                                       \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_1 (TimeDistribut (None, 3, 128)        16512                                        \n",
      "____________________________________________________________________________________________________\n",
      "gru_2 (GRU)                      (None, 256)           393984      merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            2570        gru_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 10)            0           dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 7,518,058\n",
      "Trainable params: 7,518,058\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 3600 samples, validate on 1800 samples\n",
      "Epoch 1/15\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 2.3316 - acc: 0.1069Epoch 00000: loss improved from inf to 2.33154, saving model to /usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py-00-2.3315.hdf5\n",
      "3600/3600 [==============================] - 25s - loss: 2.3315 - acc: 0.1067 - val_loss: 2.3132 - val_acc: 0.0983\n",
      "Epoch 2/15\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 2.3156 - acc: 0.1035Epoch 00001: loss improved from 2.33154 to 2.31565, saving model to /usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py-01-2.3156.hdf5\n",
      "3600/3600 [==============================] - 23s - loss: 2.3156 - acc: 0.1039 - val_loss: 2.3279 - val_acc: 0.0983\n",
      "Epoch 3/15\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 2.3190 - acc: 0.0991Epoch 00002: loss did not improve\n",
      "3600/3600 [==============================] - 22s - loss: 2.3191 - acc: 0.0989 - val_loss: 2.3066 - val_acc: 0.0983\n",
      "Epoch 4/15\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 2.3173 - acc: 0.1018Epoch 00003: loss did not improve\n",
      "3600/3600 [==============================] - 23s - loss: 2.3171 - acc: 0.1017 - val_loss: 2.3245 - val_acc: 0.1122\n",
      "Epoch 5/15\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 2.3178 - acc: 0.1080Epoch 00004: loss did not improve\n",
      "3600/3600 [==============================] - 23s - loss: 2.3180 - acc: 0.1078 - val_loss: 2.3073 - val_acc: 0.1122\n",
      "Epoch 6/15\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 2.3174 - acc: 0.1102Epoch 00005: loss did not improve\n",
      "3600/3600 [==============================] - 22s - loss: 2.3175 - acc: 0.1100 - val_loss: 2.3100 - val_acc: 0.0983\n",
      "Epoch 7/15\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 2.3148 - acc: 0.1124Epoch 00006: loss improved from 2.31565 to 2.31484, saving model to /usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py-06-2.3148.hdf5\n",
      "3600/3600 [==============================] - 22s - loss: 2.3148 - acc: 0.1128 - val_loss: 2.3091 - val_acc: 0.1122\n",
      "Epoch 8/15\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 2.3212 - acc: 0.1038Epoch 00007: loss did not improve\n",
      "3600/3600 [==============================] - 22s - loss: 2.3214 - acc: 0.1033 - val_loss: 2.3212 - val_acc: 0.1150\n",
      "Epoch 9/15\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 2.3169 - acc: 0.0996Epoch 00008: loss did not improve\n",
      "3600/3600 [==============================] - 22s - loss: 2.3171 - acc: 0.0994 - val_loss: 2.3136 - val_acc: 0.0978\n",
      "Epoch 10/15\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 2.3185 - acc: 0.1041Epoch 00009: loss did not improve\n",
      "3600/3600 [==============================] - 22s - loss: 2.3185 - acc: 0.1039 - val_loss: 2.3322 - val_acc: 0.1150\n",
      "Epoch 11/15\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 2.3143 - acc: 0.1166Epoch 00010: loss improved from 2.31484 to 2.31383, saving model to /usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py-10-2.3138.hdf5\n",
      "3600/3600 [==============================] - 22s - loss: 2.3138 - acc: 0.1169 - val_loss: 2.3339 - val_acc: 0.1150\n",
      "Epoch 12/15\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 2.3180 - acc: 0.1063Epoch 00011: loss did not improve\n",
      "3600/3600 [==============================] - 22s - loss: 2.3181 - acc: 0.1061 - val_loss: 2.3084 - val_acc: 0.1122\n",
      "Epoch 13/15\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 2.3207 - acc: 0.1099Epoch 00012: loss did not improve\n",
      "3600/3600 [==============================] - 22s - loss: 2.3208 - acc: 0.1094 - val_loss: 2.3038 - val_acc: 0.1044\n",
      "Epoch 14/15\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 2.3196 - acc: 0.1021Epoch 00013: loss did not improve\n",
      "3600/3600 [==============================] - 22s - loss: 2.3193 - acc: 0.1028 - val_loss: 2.3234 - val_acc: 0.1044\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3584/3600 [============================>.] - ETA: 0s - loss: 2.3201 - acc: 0.1080Epoch 00014: loss did not improve\n",
      "3600/3600 [==============================] - 22s - loss: 2.3201 - acc: 0.1083 - val_loss: 2.3104 - val_acc: 0.1122\n"
     ]
    }
   ],
   "source": [
    "#Part 5 -> run everything\n",
    "x_train, x_train2, y_train, x_test, x_test2, y_test = getData()\n",
    "\n",
    "classifier = getModel()\n",
    "classifier.summary()\n",
    "fitModel(x_train, x_train2, y_train, x_test, x_test2, y_test, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(x_train2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False  True False]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(x_train2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False  True False False False]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 6 0]\n"
     ]
    }
   ],
   "source": [
    "print(x_train2[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True False False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(x_train2[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Pred  : ', array([ 0.07672091,  0.1083929 ,  0.11252447,  0.1054306 ,  0.14929977,\n",
      "        0.09247572,  0.08912951,  0.07930881,  0.0907968 ,  0.09592054], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "#Test an image case\n",
    "x = get_im('/docker_shared/12Captcha/dataset/test_set/672/427.png')\n",
    "x = numpy.array(x)\n",
    "x = numpy.reshape(x, (1, 1, img_rows, img_cols))\n",
    "x = x.astype(\"float64\")\n",
    "\n",
    "x2 = numpy.array([[1,2,3]])\n",
    "\n",
    "y = ['341']\n",
    "\n",
    "pred = classifier.predict([x,x2])\n",
    "print(\"Pred  : \", pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nu\n"
     ]
    }
   ],
   "source": [
    "print(\"nu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
