{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import genfromtxt\n",
    "from keras.utils import np_utils\n",
    "import tensorflow\n",
    "import numpy\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Part 1 -> defines\n",
    "img_rows, img_cols = 128, 128\n",
    "nb_filters = 32 # nr of conv filters to use\n",
    "nb_pool = 2 # size of pooling area\n",
    "nb_conv = 3 # convolution kernel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2 -> get data\n",
    "def get_im(path):\n",
    "    # Load as grayscale\n",
    "    img = cv2.imread(path, 0)\n",
    "    # Reduce size\n",
    "    resized = cv2.resize(img, (img_cols, img_rows))\n",
    "    return resized\n",
    "\n",
    "\n",
    "def encode(str, num_rows):\n",
    "    \"\"\"\n",
    "    One hot encodes str\n",
    "    params: num_rows for keeping the num_rows the same\n",
    "    \"\"\"\n",
    "    \n",
    "    chars = '0123456789'\n",
    "    char_to_nr = dict( (ch, nr) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    nr_to_char = dict( (nr, ch) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    \n",
    "    #Matrice of zeros with the following shape [number_of_lines][max_different_chars_per_line]\n",
    "    x = np.zeros((num_rows, len(chars)))\n",
    "        \n",
    "    #Do the encoding\n",
    "    for i, ch in enumerate(str):\n",
    "        x[i, char_to_nr[ch]] = True\n",
    "        \n",
    "    return x    \n",
    "        \n",
    "def decode(x, calc_argmax = True):\n",
    "    \"\"\"\n",
    "    Decodes x and returns it\n",
    "    \"\"\"\n",
    "        \n",
    "    chars = '0123456789'\n",
    "    char_to_nr = dict( (ch, nr) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    nr_to_char = dict( (nr, ch) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    \n",
    "    if calc_argmax:\n",
    "        x = x.argmax(axis = -1)\n",
    "        \n",
    "    return ''.join(nr_to_char[x] for x in x)\n",
    "    \n",
    "def encodeAll(data):\n",
    "    chars = '0123456789'\n",
    "    MAX_LEN_Y = 3\n",
    "    \n",
    "    # [number_of_lines][max_size_of_y][total_different_chars_possible]\n",
    "    y = np.zeros( (len(data), MAX_LEN_Y, len(chars)), dtype = np.bool )\n",
    "    \n",
    "    for i, line in enumerate(data):\n",
    "        y[i] = encode(line, MAX_LEN_Y)\n",
    "    \n",
    "    return y\n",
    "\n",
    "def getDataManually(path):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "\n",
    "    for dir in os.listdir(path):\n",
    "        crtPath = os.path.join(path, dir, \"*.png\")\n",
    "        \n",
    "        files = glob.glob(crtPath)\n",
    "        for fl in files:\n",
    "             # X\n",
    "             fl = os.path.join(cwd, fl)\n",
    "             img = get_im(fl)\n",
    "             X.append(img)\n",
    "            \n",
    "             # Y\n",
    "             #crtStr = []\n",
    "             #for chr in str(dir):\n",
    "             #       crtStr.append(int(chr))\n",
    "             #y.append(crtStr)\n",
    "             \n",
    "             y.append(str(dir))\n",
    "                \n",
    "             if len(X) % 1000 == 0:\n",
    "                 print(\"Picture \" + str(len(X)) + \" added from path: \", fl)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def getData():\n",
    "    train_datagen = ImageDataGenerator()\n",
    "    test_datagen = ImageDataGenerator()\n",
    "\n",
    "    x_train, y_train = getDataManually(os.path.join(\"dataset\", \"training_set\"))\n",
    "    x_test, y_test = getDataManually(os.path.join(\"dataset\", \"test_set\"))\n",
    "    \n",
    "    x_train = numpy.array(x_train)\n",
    "    x_train = numpy.reshape(x_train, (len(x_train), 1, img_rows, img_cols))\n",
    "    x_train = x_train.astype(\"float64\")\n",
    "    train_datagen.fit(x_train, augment = False)\n",
    "\n",
    "    x_test = numpy.array(x_test)\n",
    "    x_test = numpy.reshape(x_test, (len(x_test), 1, img_rows, img_cols))\n",
    "    x_test = x_test.astype(\"float64\")\n",
    "    test_datagen.fit(x_test, augment = False)\n",
    "    \n",
    "    y_train = encodeAll(y_train)\n",
    "    y_test = encodeAll(y_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, train_datagen, test_datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Part 3 -> get the model\n",
    "def getModel():\n",
    "    max_caption_len = 3\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 3, 3, input_shape=(1, img_rows, img_cols))) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(32, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3)) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, 3, 3)) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(128, 3, 3)) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(128, 3, 3)) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2048))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(RepeatVector(max_caption_len)) \n",
    "    # the GRU below returns sequences of max_caption_len vectors of size 10 (our word embedding size)\n",
    "    model.add(GRU(10, return_sequences=True))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Part 4 -> fit the model\n",
    "def fitModel(x_train, y_train, x_test, y_test, train_datagen, test_datagen, classifier):\n",
    "    filepath = sys.argv[0] + \"-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    classifier.fit_generator(train_datagen.flow(x_train, y_train, batch_size= 32),\n",
    "                         samples_per_epoch = 10000,\n",
    "                         nb_epoch = 5,\n",
    "                         validation_data = test_datagen.flow(x_test, y_test),\n",
    "                         nb_val_samples = 5000,\n",
    "                         callbacks = callbacks_list\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Picture 1000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/512/87227.png')\n",
      "('Picture 2000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/885/10590.png')\n",
      "('Picture 3000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/287/38704.png')\n",
      "('Picture 4000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/578/19666.png')\n",
      "('Picture 5000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/730/47508.png')\n",
      "('Picture 6000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/392/19334.png')\n",
      "('Picture 7000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/517/45118.png')\n",
      "('Picture 8000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/733/81721.png')\n",
      "('Picture 9000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/873/22641.png')\n",
      "('Picture 10000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/599/84021.png')\n",
      "('Picture 11000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/649/84246.png')\n",
      "('Picture 12000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/701/74729.png')\n",
      "('Picture 13000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/866/5093.png')\n",
      "('Picture 14000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/526/29745.png')\n",
      "('Picture 15000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/522/35954.png')\n",
      "('Picture 16000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/793/95654.png')\n",
      "('Picture 17000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/839/44906.png')\n",
      "('Picture 18000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/571/97158.png')\n",
      "('Picture 19000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/731/46518.png')\n",
      "('Picture 20000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/836/96741.png')\n",
      "('Picture 21000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/518/82186.png')\n",
      "('Picture 22000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/681/73393.png')\n",
      "('Picture 23000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/533/78639.png')\n",
      "('Picture 24000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/254/26380.png')\n",
      "('Picture 25000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/171/35370.png')\n",
      "('Picture 26000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/770/51143.png')\n",
      "('Picture 27000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/422/48599.png')\n",
      "('Picture 28000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/528/76244.png')\n",
      "('Picture 29000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/416/59708.png')\n",
      "('Picture 30000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/498/1209.png')\n",
      "('Picture 31000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/855/28162.png')\n",
      "('Picture 32000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/765/3105.png')\n",
      "('Picture 33000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/867/35656.png')\n",
      "('Picture 34000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/142/34408.png')\n",
      "('Picture 35000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/625/49816.png')\n",
      "('Picture 36000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/653/39037.png')\n",
      "('Picture 37000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/527/28151.png')\n",
      "('Picture 38000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/639/84545.png')\n",
      "('Picture 39000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/994/26224.png')\n",
      "('Picture 40000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/548/4335.png')\n",
      "('Picture 41000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/948/16837.png')\n",
      "('Picture 42000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/530/26947.png')\n",
      "('Picture 43000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/539/26996.png')\n",
      "('Picture 44000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/958/50404.png')\n",
      "('Picture 45000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/209/16595.png')\n",
      "('Picture 46000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/933/10921.png')\n",
      "('Picture 47000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/264/91694.png')\n",
      "('Picture 48000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/153/27877.png')\n",
      "('Picture 49000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/458/547.png')\n",
      "('Picture 50000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/293/75228.png')\n",
      "('Picture 51000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/762/2322.png')\n",
      "('Picture 52000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/258/93681.png')\n",
      "('Picture 53000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/242/51722.png')\n",
      "('Picture 54000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/868/12031.png')\n",
      "('Picture 55000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/711/25413.png')\n",
      "('Picture 56000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/547/54331.png')\n",
      "('Picture 57000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/348/94908.png')\n",
      "('Picture 58000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/462/28726.png')\n",
      "('Picture 59000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/783/95889.png')\n",
      "('Picture 60000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/689/47011.png')\n",
      "('Picture 61000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/911/93593.png')\n",
      "('Picture 62000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/513/1022.png')\n",
      "('Picture 63000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/955/50218.png')\n",
      "('Picture 64000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/744/97597.png')\n",
      "('Picture 65000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/283/67279.png')\n",
      "('Picture 66000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/622/63934.png')\n",
      "('Picture 67000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/421/66521.png')\n",
      "('Picture 68000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/628/77545.png')\n",
      "('Picture 69000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/728/15004.png')\n",
      "('Picture 70000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/279/19065.png')\n",
      "('Picture 71000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/660/10476.png')\n",
      "('Picture 72000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/718/1158.png')\n",
      "('Picture 73000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/714/33370.png')\n",
      "('Picture 74000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/265/90450.png')\n",
      "('Picture 75000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/208/1606.png')\n",
      "('Picture 76000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/699/78140.png')\n",
      "('Picture 77000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/763/43099.png')\n",
      "('Picture 78000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/840/44737.png')\n",
      "('Picture 79000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/984/72701.png')\n",
      "('Picture 80000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/683/45992.png')\n",
      "('Picture 81000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/865/41968.png')\n",
      "('Picture 82000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/869/66947.png')\n",
      "('Picture 83000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/906/6543.png')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Picture 84000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/678/18693.png')\n",
      "('Picture 85000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/556/26068.png')\n",
      "('Picture 86000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/989/90001.png')\n",
      "('Picture 87000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/612/30842.png')\n",
      "('Picture 88000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/248/91021.png')\n",
      "('Picture 89000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/184/76528.png')\n",
      "('Picture 90000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/580/51899.png')\n",
      "('Picture 91000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/448/2782.png')\n",
      "('Picture 92000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/559/74148.png')\n",
      "('Picture 93000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/637/31360.png')\n",
      "('Picture 94000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/484/70282.png')\n",
      "('Picture 95000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/853/13314.png')\n",
      "('Picture 96000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/759/82606.png')\n",
      "('Picture 97000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/118/29462.png')\n",
      "('Picture 98000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/978/40417.png')\n",
      "('Picture 99000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/951/47744.png')\n",
      "('Picture 100000 added from path: ', '/docker_shared/12Captcha/dataset/training_set/732/82967.png')\n",
      "('Picture 1000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/885/1419.png')\n",
      "('Picture 2000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/578/34989.png')\n",
      "('Picture 3000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/392/25810.png')\n",
      "('Picture 4000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/733/27350.png')\n",
      "('Picture 5000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/128/47852.png')\n",
      "('Picture 6000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/499/16794.png')\n",
      "('Picture 7000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/127/15622.png')\n",
      "('Picture 8000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/755/19433.png')\n",
      "('Picture 9000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/371/36523.png')\n",
      "('Picture 10000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/432/40677.png')\n",
      "('Picture 11000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/180/21001.png')\n",
      "('Picture 12000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/677/1856.png')\n",
      "('Picture 13000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/320/22383.png')\n",
      "('Picture 14000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/331/45768.png')\n",
      "('Picture 15000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/197/34376.png')\n",
      "('Picture 16000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/747/2766.png')\n",
      "('Picture 17000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/751/6595.png')\n",
      "('Picture 18000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/562/5546.png')\n",
      "('Picture 19000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/358/48477.png')\n",
      "('Picture 20000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/450/29712.png')\n",
      "('Picture 21000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/482/771.png')\n",
      "('Picture 22000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/995/16300.png')\n",
      "('Picture 23000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/851/16993.png')\n",
      "('Picture 24000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/822/2948.png')\n",
      "('Picture 25000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/655/45753.png')\n",
      "('Picture 26000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/669/31855.png')\n",
      "('Picture 27000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/207/16919.png')\n",
      "('Picture 28000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/588/18578.png')\n",
      "('Picture 29000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/697/39688.png')\n",
      "('Picture 30000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/689/10332.png')\n",
      "('Picture 31000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/779/10538.png')\n",
      "('Picture 32000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/835/10380.png')\n",
      "('Picture 33000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/479/1840.png')\n",
      "('Picture 34000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/628/8744.png')\n",
      "('Picture 35000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/279/32690.png')\n",
      "('Picture 36000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/474/130.png')\n",
      "('Picture 37000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/265/34037.png')\n",
      "('Picture 38000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/246/19104.png')\n",
      "('Picture 39000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/780/7105.png')\n",
      "('Picture 40000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/683/45679.png')\n",
      "('Picture 41000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/635/44642.png')\n",
      "('Picture 42000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/350/48166.png')\n",
      "('Picture 43000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/326/40809.png')\n",
      "('Picture 44000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/493/47666.png')\n",
      "('Picture 45000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/980/16029.png')\n",
      "('Picture 46000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/396/7681.png')\n",
      "('Picture 47000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/565/43131.png')\n",
      "('Picture 48000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/759/49871.png')\n",
      "('Picture 49000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/592/6827.png')\n",
      "('Picture 50000 added from path: ', '/docker_shared/12Captcha/dataset/test_set/732/20117.png')\n",
      "('Shape of y_train: ', (100000, 3, 10))\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 32, 126, 126)  320         convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 32, 126, 126)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 32, 124, 124)  9248        activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 32, 124, 124)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 32, 62, 62)    0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 64, 60, 60)    18496       maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 64, 60, 60)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 64, 58, 58)    36928       activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 64, 58, 58)    0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 64, 29, 29)    0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 128, 27, 27)   73856       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 128, 27, 27)   0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 128, 25, 25)   147584      activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 128, 25, 25)   0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 128, 12, 12)   0           activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 18432)         0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1024)          18875392    flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 1024)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 1024)          0           activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 2048)          2099200     dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 2048)          0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "repeatvector_1 (RepeatVector)    (None, 3, 2048)       0           activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "gru_1 (GRU)                      (None, 3, 10)         61770       repeatvector_1[0][0]             \n",
      "====================================================================================================\n",
      "Total params: 21,322,794\n",
      "Trainable params: 21,322,794\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 9984/10000 [============================>.] - ETA: 0s - loss: 0.1008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/engine/training.py:1527: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: loss improved from inf to 0.10084, saving model to /usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py-00-0.1008.hdf5\n",
      "10016/10000 [==============================] - 69s - loss: 0.1008 - val_loss: 0.1000\n",
      "Epoch 2/5\n",
      " 9984/10000 [============================>.] - ETA: 0s - loss: 0.1000Epoch 00001: loss improved from 0.10084 to 0.10000, saving model to /usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py-01-0.1000.hdf5\n",
      "10016/10000 [==============================] - 68s - loss: 0.1000 - val_loss: 0.1000\n",
      "Epoch 3/5\n",
      " 9984/10000 [============================>.] - ETA: 0s - loss: 0.1000Epoch 00002: loss did not improve\n",
      "10016/10000 [==============================] - 68s - loss: 0.1000 - val_loss: 0.1000\n",
      "Epoch 4/5\n",
      " 9984/10000 [============================>.] - ETA: 0s - loss: 0.1000Epoch 00003: loss did not improve\n",
      "10016/10000 [==============================] - 68s - loss: 0.1000 - val_loss: 0.1000\n",
      "Epoch 5/5\n",
      " 1824/10000 [====>.........................] - ETA: 48s - loss: 0.1000"
     ]
    }
   ],
   "source": [
    "#Part 5 -> run everything\n",
    "x_train, y_train, x_test, y_test, train_datagen, test_datagen = getData()\n",
    "\n",
    "print(\"Shape of y_train: \", y_train.shape)\n",
    "classifier = getModel()\n",
    "\n",
    "print(classifier.summary())\n",
    "\n",
    "fitModel(x_train, y_train, x_test, y_test, train_datagen, test_datagen, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test an image case\n",
    "x = get_im('/docker_shared/12Captcha/dataset/test_set/341/10373.png')\n",
    "x = numpy.array(x)\n",
    "x = numpy.reshape(x, (1, 1, img_rows, img_cols))\n",
    "x = x.astype(\"float64\")\n",
    "    \n",
    "y = ['341']\n",
    "y = encodeAll(y)\n",
    "print(\"y Encoded: \", y)\n",
    "\n",
    "pred = classifier.predict(x)\n",
    "predDecoded = decode(pred[0])\n",
    "print(\"Pred  : \", predDecoded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"da\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
