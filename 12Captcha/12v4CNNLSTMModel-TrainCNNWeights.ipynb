{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name Conv2DTranspose",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-957242a625a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUpSampling2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2DTranspose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name Conv2DTranspose"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Merge\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import genfromtxt\n",
    "from keras.utils import np_utils\n",
    "import tensorflow\n",
    "import numpy\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import copy\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Part 1 -> defines\n",
    "img_channels, img_rows, img_cols = 1, 128, 128\n",
    "max_caption_len = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Part 2 -> get data\n",
    "def get_im(path):\n",
    "    # Load as grayscale\n",
    "    img = cv2.imread(path, 0)\n",
    "    # Reduce size\n",
    "    resized = cv2.resize(img, (img_cols, img_rows))\n",
    "    return resized\n",
    "\n",
    "\n",
    "def encode(str, num_rows):\n",
    "    \"\"\"\n",
    "    One hot encodes str\n",
    "    params: num_rows for keeping the num_rows the same\n",
    "    \"\"\"\n",
    "    \n",
    "    chars = '0123456789'\n",
    "    char_to_nr = dict( (ch, nr) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    nr_to_char = dict( (nr, ch) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    \n",
    "    #Matrice of zeros with the following shape [number_of_lines][max_different_chars_per_line]\n",
    "    x = np.zeros((num_rows, len(chars)))\n",
    "        \n",
    "    #Do the encoding\n",
    "    for i, ch in enumerate(str):\n",
    "        x[i, char_to_nr[ch]] = True\n",
    "        \n",
    "    return x    \n",
    "        \n",
    "def decode(x, calc_argmax = True):\n",
    "    \"\"\"\n",
    "    Decodes x and returns it\n",
    "    \"\"\"\n",
    "        \n",
    "    chars = '0123456789'\n",
    "    char_to_nr = dict( (ch, nr) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    nr_to_char = dict( (nr, ch) for nr, ch in enumerate(sorted(set(chars))) )\n",
    "    \n",
    "    if calc_argmax:\n",
    "        x = x.argmax(axis = -1)\n",
    "        \n",
    "    return ''.join(nr_to_char[x] for x in x)\n",
    "    \n",
    "def encodeAll(data):\n",
    "    chars = '0123456789'\n",
    "    MAX_LEN_Y = 1\n",
    "    \n",
    "    # [number_of_lines][total_different_chars_possible]\n",
    "    y = np.zeros( (len(data), len(chars)), dtype = np.bool )\n",
    "    \n",
    "    for i, line in enumerate(data):\n",
    "        y[i] = encode(line, MAX_LEN_Y)\n",
    "    \n",
    "    return y\n",
    "\n",
    "def pad(str, size):\n",
    "    newStr = copy.deepcopy(str)\n",
    "    while(len(newStr) < size):\n",
    "        newStr.append(0)\n",
    "        \n",
    "    return newStr\n",
    "\n",
    "def getDataManually(path):\n",
    "    X = []\n",
    "    X2 = []\n",
    "    y = []\n",
    "    \n",
    "\n",
    "    for dir in os.listdir(path):\n",
    "        crtPath = os.path.join(path, dir, \"*.png\")\n",
    "        \n",
    "        files = glob.glob(crtPath)\n",
    "        for fl in files:\n",
    "             # X\n",
    "             fl = os.path.join(cwd, fl)\n",
    "             img = get_im(fl)\n",
    "            \n",
    "             # Y\n",
    "             crtSeq = ''\n",
    "             crtSeqList = []\n",
    "             \n",
    "             X.append(img)\n",
    "             X2.append( pad(crtSeqList, 3) )\n",
    "             y.append( str(dir[0]) )\n",
    "                \n",
    "             for i in range( len(str(dir)) - 1 ):\n",
    "                    crtSeq += dir[i]\n",
    "                    crtSeqList.append( int(dir[i]) )\n",
    "                    \n",
    "                    X.append(img)\n",
    "                    X2.append( pad(crtSeqList, 3) )\n",
    "                    y.append( str(dir[i + 1]) )\n",
    "                    \n",
    "             if len(X) % 1000 == 0:\n",
    "                 print(\"Picture \" + str(len(X)) + \" added from path: \", fl)\n",
    "    \n",
    "    return X, X2, y\n",
    "\n",
    "def getData():\n",
    "    x_train, x_train2, y_train = getDataManually(os.path.join(\"dataset\", \"training_set\"))\n",
    "    x_test, x_test2, y_test = getDataManually(os.path.join(\"dataset\", \"test_set\"))\n",
    "    \n",
    "    x_train = numpy.array(x_train)\n",
    "    x_train = numpy.reshape(x_train, (len(x_train), 1, img_rows, img_cols))\n",
    "    x_train = x_train.astype(\"float64\")\n",
    "\n",
    "    x_test = numpy.array(x_test)\n",
    "    x_test = numpy.reshape(x_test, (len(x_test), 1, img_rows, img_cols))\n",
    "    x_test = x_test.astype(\"float64\")\n",
    "\n",
    "    x_train2 = numpy.array(x_train2)\n",
    "    x_test2 = numpy.array(x_test2)\n",
    "\n",
    "    y_train = encodeAll(y_train)\n",
    "    y_test = encodeAll(y_test)\n",
    "    \n",
    "    return x_train, x_train2, y_train, x_test, x_test2, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 3 -> get the model\n",
    "def getModel():\n",
    "    max_caption_len = 3\n",
    "    vocab_size = 10\n",
    "\n",
    "    # first, let's define an image model that\n",
    "    # will encode pictures into 128-dimensional vectors.\n",
    "    # it should be initialized with pre-trained weights.\n",
    "    image_model = Sequential()\n",
    "    \n",
    "    #ENCODER PART\n",
    "    image_model.add(Convolution2D(32, 3, 3, border_mode='valid', input_shape=(img_channels, img_rows, img_cols)))\n",
    "    image_model.add(Activation('relu'))\n",
    "    image_model.add(Convolution2D(32, 3, 3))\n",
    "    image_model.add(Activation('relu'))\n",
    "    image_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    image_model.add(Convolution2D(64, 3, 3, border_mode='valid'))\n",
    "    image_model.add(Activation('relu'))\n",
    "    image_model.add(Convolution2D(64, 3, 3))\n",
    "    image_model.add(Activation('relu'))\n",
    "    image_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    image_model.add(Flatten())\n",
    "    image_model.add(Dense(128))\n",
    "    image_model.add(Activation('relu'))\n",
    "    #Decoder part\n",
    "    \n",
    "    image_model.add( Dense(29*29*64) )\n",
    "    image_model.add( Activation('relu'))\n",
    "    image_model.add( Reshape( (64, 29, 29)) )\n",
    "    \n",
    "    image_model.add( UpSampling2D((2, 2)) )\n",
    "    image_model.add( Conv2DTranspose(64, 3, 3, border_mode='same') ) \n",
    "    image_model.add( Activation('relu') )\n",
    "    image_model.add( Conv2DTranspose(64, 3, 3, border_mode='same') )\n",
    "    image_model.add( Activation('relu') )\n",
    "    image_model.add( UpSampling2D((2, 2)) )\n",
    "        \n",
    "    #image_model.add( UpSampling2D((2, 2)) )\n",
    "    #image_model.add( Convolution2D(32, 3, 3) )\n",
    "    #image_model.add( Activation('relu') )\n",
    "    #image_model.add( Convolution2D(32, 3, 3, border_mode='valid') )\n",
    "    #image_model.add( Activation('relu') )\n",
    "    \n",
    "    \n",
    "    image_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "    # \"images\" is a numpy float array of shape (num_samples, num_channels=3, width, height).\n",
    "    # \"captions\" is a numpy integer array of shape (num_samples, max_caption_len)\n",
    "    # containing word index sequences representing partial captions.\n",
    "    # \"next_words\" is a numpy float array of shape (num_samples, vocab_size)\n",
    "    # containing a categorical encoding (0s and 1s) of the next word in the corresponding\n",
    "    # partial caption.\n",
    "    #model.fit([images, partial_captions], next_words, batch_size=16, epochs=100)\n",
    "\n",
    "    return image_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 4 -> fit the model\n",
    "def fitModel(x_train, x_train2, y_train, x_test, x_test2, y_test, model):\n",
    "    filepath = \"12v4CNNLSTMModel-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    #model.fit(x_train, x_train, \n",
    "    #          batch_size=16, \n",
    "    #          nb_epoch=15, \n",
    "    #          validation_data = (x_test, x_test),\n",
    "    #          callbacks = callbacks_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Part 5 -> run everything\n",
    "x_train, x_train2, y_train, x_test, x_test2, y_test = getData()\n",
    "\n",
    "classifier = getModel()\n",
    "classifier.summary()\n",
    "fitModel(x_train, x_train2, y_train, x_test, x_test2, y_test, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train2[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train2[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test an image case\n",
    "x = get_im('/docker_shared/12Captcha/dataset/test_set/672/427.png')\n",
    "x = numpy.array(x)\n",
    "x = numpy.reshape(x, (1, 1, img_rows, img_cols))\n",
    "x = x.astype(\"float64\")\n",
    "\n",
    "x2 = numpy.array([[1,2,3]])\n",
    "\n",
    "y = ['341']\n",
    "\n",
    "pred = classifier.predict([x,x2])\n",
    "print(\"Pred  : \", pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"nu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}